{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from model import FaceModel,FaceModelCenter,FaceModelSoftmax\n",
    "from eval_metrics import evaluate\n",
    "#from logger import Logger\n",
    "from LFWDataset import LFWDataset\n",
    "from TripletFaceDataset import TripletFaceDataset\n",
    "from PIL import Image\n",
    "from utils import PairwiseDistance,display_triplet_distance,display_triplet_distance_test\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4990\r\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/jw4937/deeplearningdataset/train | grep m | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4990\r\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/jw4937/deeplearningdataset/test | grep m | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Face Recognition')\n",
    "# Model options\n",
    "parser.add_argument('--dataroot', type=str, default='/scratch/jw4937/deeplearningdataset/train',#default='/scratch/hb1500/deeplearningdataset/train'\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--testdataroot', type=str, default='/scratch/jw4937/deeplearningdataset/test',#default='/media/lior/LinuxHDD/datasets/vgg_face_dataset/aligned'\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--lfw-dir', type=str, default='/scratch/jw4937/deeplearningdataset/lfw',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--lfw-pairs-path', type=str, default='lfw_pairs.txt',\n",
    "                    help='path to pairs file')\n",
    "\n",
    "parser.add_argument('--log-dir', default='/scratch/jw4937/logdir_triplet_loss',\n",
    "                    help='folder to output model checkpoints')\n",
    "\n",
    "parser.add_argument('--resume',\n",
    "                    default='/scratch/jw4937/resume/run-optim_adam-lr0.001-wd0.0-embeddings512-center0.5-MSCeleb/checkpoint_11.pth',\n",
    "                    type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--epochs', type=int, default=20, metavar='E',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "# Training options\n",
    "# parser.add_argument('--embedding-size', type=int, default=256, metavar='ES',\n",
    "#                     help='Dimensionality of the embedding')\n",
    "\n",
    "parser.add_argument('--center_loss_weight', type=float, default=0.5, help='weight for center loss')\n",
    "parser.add_argument('--alpha', type=float, default=0.5, help='learning rate of the centers')\n",
    "parser.add_argument('--embedding-size', type=int, default=512, metavar='ES',\n",
    "                    help='Dimensionality of the embedding')\n",
    "\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='BS',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=64, metavar='BST',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--n-triplets', type=int, default=50000, metavar='N',\n",
    "                    help='how many triplets will generate from the dataset,default=1000000')\n",
    "parser.add_argument('--margin', type=float, default=1.0, metavar='MARGIN',\n",
    "                    help='the margin value for the triplet loss function (default: 1.0')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "\n",
    "parser.add_argument('--lr-decay', default=1e-4, type=float, metavar='LRD',\n",
    "                    help='learning rate decay ratio (default: 1e-4')\n",
    "parser.add_argument('--wd', default=0.0, type=float,\n",
    "                    metavar='W', help='weight decay (default: 0.0)')\n",
    "parser.add_argument('--optimizer', default='adam', type=str,\n",
    "                    metavar='OPT', help='The optimizer to use (default: Adagrad)')\n",
    "# Device options\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--gpu-id', default='0', type=str,\n",
    "                    help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "parser.add_argument('--seed', type=int, default=0, metavar='S',\n",
    "                    help='random seed (default: 0)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='LI',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "args = parser.parse_args(args = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4247/50000 [00:00<00:01, 41340.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50000 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 5522/50000 [00:00<00:02, 21084.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 8135/50000 [00:00<00:01, 23661.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 12173/50000 [00:00<00:01, 27446.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16229/50000 [00:00<00:01, 29854.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 20341/50000 [00:00<00:00, 31609.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 24442/50000 [00:00<00:00, 32871.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 28561/50000 [00:00<00:00, 33856.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 32667/50000 [00:00<00:00, 34620.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 36806/50000 [00:01<00:00, 35266.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 40891/50000 [00:01<00:00, 35756.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 45010/50000 [00:01<00:00, 36191.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49142/50000 [00:01<00:00, 36572.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50000/50000 [00:01<00:00, 36473.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 166/6000 [00:00<00:03, 1614.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 328/6000 [00:00<00:03, 1606.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 454/6000 [00:00<00:03, 1491.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 634/6000 [00:00<00:03, 1567.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 796/6000 [00:00<00:03, 1577.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 945/6000 [00:00<00:03, 1563.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 1126/6000 [00:00<00:03, 1596.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 1323/6000 [00:00<00:02, 1642.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 1500/6000 [00:00<00:02, 1655.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 1668/6000 [00:01<00:02, 1644.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 1875/6000 [00:01<00:02, 1682.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 2060/6000 [00:01<00:02, 1695.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 2239/6000 [00:01<00:02, 1691.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 2459/6000 [00:01<00:02, 1727.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 2648/6000 [00:01<00:01, 1731.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 2834/6000 [00:01<00:01, 1724.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 3036/6000 [00:01<00:01, 1741.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 3233/6000 [00:01<00:01, 1753.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 3422/6000 [00:01<00:01, 1755.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 3613/6000 [00:02<00:01, 1762.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 3801/6000 [00:02<00:01, 1755.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 3982/6000 [00:02<00:01, 1747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 4189/6000 [00:02<00:01, 1760.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 4373/6000 [00:02<00:00, 1751.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 4549/6000 [00:02<00:00, 1740.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 4737/6000 [00:02<00:00, 1745.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 4929/6000 [00:02<00:00, 1751.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 5109/6000 [00:02<00:00, 1749.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 5286/6000 [00:03<00:00, 1747.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 5479/6000 [00:03<00:00, 1753.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 5659/6000 [00:03<00:00, 1751.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 5836/6000 [00:03<00:00, 1747.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6000/6000 [00:03<00:00, 1753.18it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# set the device to use by setting CUDA_VISIBLE_DEVICES env variable in\n",
    "# order to prevent any memory allocation on unused GPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_id\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "if args.cuda:\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "#LOG_DIR = args.log_dir + '/run-optim_{}-lr{}-wd{}-embeddings{}-center_loss{}-MSCeleb'.format(args.optimizer, args.lr, args.wd,args.embedding_size,args.center_loss_weight)\n",
    "LOG_DIR = args.log_dir + '/run-optim_{}-n{}-lr{}-wd{}-m{}-embeddings{}-msceleb-alpha10'\\\n",
    "    .format(args.optimizer, args.n_triplets, args.lr, args.wd,\n",
    "            args.margin,args.embedding_size)\n",
    "\n",
    "# create logger\n",
    "#logger = Logger(LOG_DIR)\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if args.cuda else {}\n",
    "l2_dist = PairwiseDistance(2)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                         transforms.Resize((96,96)),\n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize(mean = [ 0.5, 0.5, 0.5 ],\n",
    "                                               std = [ 0.5, 0.5, 0.5 ])\n",
    "                     ])\n",
    "\n",
    "#train_dir = TripletFaceDataset(args.dataroot,transform=transform)\n",
    "train_dir = TripletFaceDataset(dir=args.dataroot,n_triplets=args.n_triplets,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dir,batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "#testacc_dir = TripletFaceDataset(dir=args.dataroot,n_triplets=args.n_triplets,transform=transform)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dir,batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "#testaccuracy_loader = torch.utils.data.DataLoader(testacc_dir,\n",
    "#    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "testacc_dir = ImageFolder(args.testdataroot,transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    LFWDataset(dir=args.lfw_dir,pairs_path=args.lfw_pairs_path,\n",
    "                     transform=transform),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "testaccuracy_loader = torch.utils.data.DataLoader(testacc_dir,\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parsed options:\n",
      "{'dataroot': '/scratch/jw4937/deeplearningdataset/train', 'testdataroot': '/scratch/jw4937/deeplearningdataset/test', 'lfw_dir': '/scratch/jw4937/deeplearningdataset/lfw', 'lfw_pairs_path': 'lfw_pairs.txt', 'log_dir': '/scratch/jw4937/logdir_triplet_loss', 'resume': '/scratch/jw4937/resume/run-optim_adam-lr0.001-wd0.0-embeddings512-center0.5-MSCeleb/checkpoint_11.pth', 'start_epoch': 0, 'epochs': 20, 'center_loss_weight': 0.5, 'alpha': 0.5, 'embedding_size': 512, 'batch_size': 64, 'test_batch_size': 64, 'n_triplets': 50000, 'margin': 1.0, 'lr': 0.001, 'beta1': 0.5, 'lr_decay': 0.0001, 'wd': 0.0, 'optimizer': 'adam', 'no_cuda': False, 'gpu_id': '0', 'seed': 0, 'log_interval': 10, 'cuda': True}\n",
      "\n",
      "\n",
      "Number of Classes:\n",
      "4990\n",
      "\n",
      "you are using gpu\n",
      "=> no checkpoint found at /scratch/jw4937/resume/run-optim_adam-lr0.001-wd0.0-embeddings512-center0.5-MSCeleb/checkpoint_11.pth\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A/home/jw4937/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:119: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n",
      "\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9.517541 \t # of Selected Triplets: 61: : 0it [00:03, ?it/s]\u001b[A\u001b[A\u001b[A/home/jw4937/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:124: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n",
      "\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9.517541 \t # of Selected Triplets: 61: : 1it [00:03,  3.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\u001b[AException in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/tqdm-4.19.4-py3.6.egg/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/jw4937/py3.6.3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9.517541 \t # of Selected Triplets: 61: : 2it [00:05,  2.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9.517541 \t # of Selected Triplets: 61: : 3it [00:08,  2.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9.517541 \t # of Selected Triplets: 61: : 4it [00:08,  2.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/jw4937/Face-recognition/src/TripletFaceDataset.py\", line 77, in __getitem__\n    img_a, img_p, img_n = transform(a), transform(p), transform(n)\n  File \"/home/jw4937/Face-recognition/src/TripletFaceDataset.py\", line 70, in transform\n    img = self.loader(img_path)\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n    return pil_loader(path)\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/PIL/Image.py\", line 2590, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='/scratch/jw4937/deeplearningdataset/train/m.012x5/2-FaceId-0.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-06839f0fefda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mdisplay_triplet_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/train_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-06839f0fefda>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;31m#         testRecall(test_loader, model, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-06839f0fefda>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_n\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdata_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/tqdm-4.19.4-py3.6.egg/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Traceback (most recent call last):\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/jw4937/Face-recognition/src/TripletFaceDataset.py\", line 77, in __getitem__\n    img_a, img_p, img_n = transform(a), transform(p), transform(n)\n  File \"/home/jw4937/Face-recognition/src/TripletFaceDataset.py\", line 70, in transform\n    img = self.loader(img_path)\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n    return pil_loader(path)\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 51, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/jw4937/py3.6.3/lib/python3.6/site-packages/PIL/Image.py\", line 2590, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='/scratch/jw4937/deeplearningdataset/train/m.012x5/2-FaceId-0.jpg'>\n"
     ]
    }
   ],
   "source": [
    "class TripletMarginLoss(Function):\n",
    "    \"\"\"Triplet loss function.\n",
    "    \"\"\"\n",
    "    def __init__(self, margin):\n",
    "        super(TripletMarginLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pdist = PairwiseDistance(2)  # norm 2\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        d_p = self.pdist.forward(anchor, positive)\n",
    "        d_n = self.pdist.forward(anchor, negative)\n",
    "\n",
    "        dist_hinge = torch.clamp(self.margin + d_p - d_n, min=0.0)\n",
    "        loss = torch.mean(dist_hinge)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, model, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader))\n",
    "    labels, distances = [], []\n",
    "\n",
    "\n",
    "    for batch_idx, (data_a, data_p, data_n,label_p,label_n) in pbar:\n",
    "\n",
    "        data_a, data_p, data_n = data_a.cuda(), data_p.cuda(), data_n.cuda()\n",
    "        data_a, data_p, data_n = Variable(data_a), Variable(data_p), \\\n",
    "                                 Variable(data_n)\n",
    "\n",
    "        # compute output\n",
    "        out_a, out_p, out_n = model(data_a), model(data_p), model(data_n)\n",
    "\n",
    "        # Choose the hard negatives\n",
    "        d_p = l2_dist.forward(out_a, out_p)\n",
    "        d_n = l2_dist.forward(out_a, out_n)\n",
    "#        all = (d_n - d_p < args.margin).cpu().data.numpy().flatten()\n",
    "        all_ = (d_n - d_p < args.margin).cpu().data.numpy().flatten()\n",
    "        hard_triplets = np.where(all_ == 1)\n",
    "        if len(hard_triplets[0]) == 0:\n",
    "            continue\n",
    "        out_selected_a = Variable(torch.from_numpy(out_a.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "        out_selected_p = Variable(torch.from_numpy(out_p.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "        out_selected_n = Variable(torch.from_numpy(out_n.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "\n",
    "        selected_data_a = Variable(torch.from_numpy(data_a.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "        selected_data_p = Variable(torch.from_numpy(data_p.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "        selected_data_n = Variable(torch.from_numpy(data_n.cpu().data.numpy()[hard_triplets]).cuda())\n",
    "\n",
    "        selected_label_p = torch.from_numpy(label_p.cpu().numpy()[hard_triplets])\n",
    "        selected_label_n= torch.from_numpy(label_n.cpu().numpy()[hard_triplets])\n",
    "        triplet_loss = TripletMarginLoss(args.margin).forward(out_selected_a, out_selected_p, out_selected_n)\n",
    "\n",
    "        cls_a = model.forward_classifier(selected_data_a)\n",
    "        cls_p = model.forward_classifier(selected_data_p)\n",
    "        cls_n = model.forward_classifier(selected_data_n)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        predicted_labels = torch.cat([cls_a,cls_p,cls_n])\n",
    "        true_labels = torch.cat([Variable(selected_label_p.cuda()),Variable(selected_label_p.cuda()),Variable(selected_label_n.cuda())])\n",
    "\n",
    "        cross_entropy_loss = criterion(predicted_labels.cuda(),true_labels.cuda())\n",
    "\n",
    "        loss = cross_entropy_loss + triplet_loss\n",
    "        # compute gradient and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update the optimizer learning rate\n",
    "        adjust_learning_rate(optimizer)\n",
    "\n",
    "        # log loss value\n",
    "        #logger.log_value('triplet_loss', triplet_loss.data[0]).step()\n",
    "        #logger.log_value('cross_entropy_loss', cross_entropy_loss.data[0]).step()\n",
    "        #logger.log_value('total_loss', loss.data[0]).step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\t # of Selected Triplets: {}'.format(\n",
    "                    epoch, batch_idx * len(data_a), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.data[0],len(hard_triplets[0])))\n",
    "            file = open('./log_triplet_loss/Train_Accuracy.txt','a') \n",
    "            file.write('Train Epoch: {} [{}/{} ({:.0f}%)]\\\\tLoss: {:.6f}\\\\t# of Selected Triplets: {} \\n'.format(\n",
    "                    epoch, batch_idx * len(data_a), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.data[0],len(hard_triplets[0])))\n",
    "            file.close()\n",
    "\n",
    "\n",
    "        dists = l2_dist.forward(out_selected_a,out_selected_n) #torch.sqrt(torch.sum((out_a - out_n) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy())\n",
    "        labels.append(np.zeros(dists.size(0)))\n",
    "\n",
    "\n",
    "        dists = l2_dist.forward(out_selected_a,out_selected_p)#torch.sqrt(torch.sum((out_a - out_p) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy())\n",
    "        labels.append(np.ones(dists.size(0)))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    labels = np.array([sublabel for label in labels for sublabel in label])\n",
    "    distances = np.array([subdist for dist in distances for subdist in dist])\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances,labels)\n",
    "    print('\\33[91mTrain set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    #logger.log_value('Train Accuracy', np.mean(accuracy))\n",
    "    if not os.path.exists(LOG_DIR):\n",
    "        os.mkdir(LOG_DIR)\n",
    "    plot_roc(fpr,tpr,figure_name=\"roc_train_epoch_{}.png\".format(epoch))\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()},\n",
    "               '{}/checkpoint_{}.pth'.format(LOG_DIR, epoch))\n",
    "\n",
    "\n",
    "#     if not os.path.exists(LOG_DIR):\n",
    "#         os.mkdir(LOG_DIR)\n",
    "#     torch.save({'epoch': epoch + 1,\n",
    "#                 'state_dict': model.state_dict(),\n",
    "#                 'centers': model.centers},\n",
    "#             '{}/checkpoint_{}.pth'.format(LOG_DIR, epoch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(test_loader, model, epoch):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    labels, distances = [], []\n",
    "\n",
    "    pbar = tqdm(enumerate(test_loader))\n",
    "    for batch_idx, (data_a, data_p, label) in pbar:\n",
    "        if args.cuda:\n",
    "            data_a, data_p = data_a.cuda(), data_p.cuda()\n",
    "        data_a, data_p, label = Variable(data_a, volatile=True), \\\n",
    "                                Variable(data_p, volatile=True), Variable(label)\n",
    "\n",
    "        # compute output\n",
    "        out_a, out_p = model(data_a), model(data_p)\n",
    "        dists = l2_dist.forward(out_a,out_p)#torch.sqrt(torch.sum((out_a - out_p) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy())\n",
    "        labels.append(label.data.cpu().numpy())\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description('Test Epoch: {} [{}/{} ({:.0f}%)]'.format(\n",
    "                epoch, batch_idx * len(data_a), len(test_loader.dataset),\n",
    "                100. * batch_idx / len(test_loader)))\n",
    "            \n",
    "    #print(distances)\n",
    "    labels = np.array([sublabel for label in labels for sublabel in label])\n",
    "    distances = np.array([subdist for dist in distances for subdist in dist])\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances,labels)\n",
    "    print('\\33[91mTest set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    #logger.log_value('Test Accuracy', np.mean(accuracy))\n",
    "    file = open('./log_triplet_loss/Verification_Accuracy.txt','a') \n",
    "    file.write('Test Epoch: {} \\t Average Accuracy : {:.8f}\\n'.format(epoch,np.mean(accuracy)))\n",
    "    file.close()\n",
    "    plot_roc(fpr,tpr,figure_name=\"roc_test_epoch_{}.png\".format(epoch))\n",
    "\n",
    "def testaccuracy(test_loader,model,epoch):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(test_loader))\n",
    "    top1 = AverageMeter()\n",
    "    for batch_idx, (data, label) in pbar:\n",
    "        data_v = Variable(data.cuda())\n",
    "        target_value = Variable(label)\n",
    "\n",
    "        # compute output\n",
    "        prediction = model.forward_classifier(data_v)\n",
    "        prec = accuracy(prediction.data, label.cuda(), topk=(1,))\n",
    "        top1.update(prec[0], data_v.size(0))\n",
    "        #correct += accuracy(prediction.data, label.cuda(), topk=(1,))[0]*data_v.size(0)\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                'Test Epoch: {} [{}/{} ({:.0f}%)]\\t'\n",
    "                'Test Prec@1 {:.2f} ({:.2f})'.format(\n",
    "                    epoch, batch_idx * len(data_v), len(test_loader.dataset),\n",
    "                    100. * batch_idx / len(test_loader),\n",
    "                    float(top1.val[0]),float(top1.avg[0])))\n",
    "            file = open('./log_triplet_loss/Recognition_Accuracy.txt','a') \n",
    "            file.write('Test Epoch: {} [{}/{} ({:.0f}%)]\\t'\n",
    "                'Test Recognition Prec@1 {:.2f} ({:.2f}) \\n'.format(\n",
    "                    epoch, batch_idx * len(data_v), len(test_loader.dataset),\n",
    "                    100. * batch_idx / len(test_loader),\n",
    "                    float(top1.val[0]),float(top1.avg[0])))\n",
    "            file.close()\n",
    "            \n",
    "def testRecall(test_loader,model,epoch):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(test_loader))\n",
    "    top1 = AverageMeter()\n",
    "    for batch_idx, (data, label) in pbar:\n",
    "        data = Variable(data.cuda())\n",
    "        label = Variable(label)\n",
    "        # compute output\n",
    "        out_data = model(data)[0]\n",
    "        \n",
    "        distance_matrix = get_distance(out_data.cpu().data.numpy())\n",
    "        label = label.asnumpy\n",
    "        \n",
    "        names = []\n",
    "        accs = []\n",
    "        \n",
    "        for k in [1, 2, 4, 8, 16]:\n",
    "            names.append('Recall@%d' % k)\n",
    "            correct, cnt = 0.0, 0.0\n",
    "            for i in range(out_data.shape[0]):\n",
    "                d_mat[i, i] = 1e10\n",
    "                nns = argpartition(d_mat[i], k)[:k]\n",
    "                if any(labels[i] == labels[nn] for nn in nns):\n",
    "                    correct += 1\n",
    "                cnt += 1\n",
    "            accs.append(correct/cnt)\n",
    "        \n",
    "        #correct += accuracy(prediction.data, label.cuda(), topk=(1,))[0]*data_v.size(0)\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                'Test Epoch: {} [{}/{} ({:.0f}%)]\\t'\n",
    "                'Test Recognition Prec@1 {:.2f} \\n'.format(\n",
    "                    epoch, batch_idx * len(data_v), len(test_loader.dataset),\n",
    "                    100. * batch_idx / len(test_loader),\n",
    "                    float(accs[0])))\n",
    "            file = open('./log_triplet_loss/Recognition_Recall.txt','a') \n",
    "            file.write('Test Epoch: {} [{}/{} ({:.0f}%)]\\t'\n",
    "                'Test Recognition Prec@1 {:.2f} \\n'.format(\n",
    "                    epoch, batch_idx * len(data_v), len(test_loader.dataset),\n",
    "                    100. * batch_idx / len(test_loader),\n",
    "                    float(accs[0])))\n",
    "            file.close()\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:    \n",
    "            for name, val_acc in zip(names, val_accs):\n",
    "                \n",
    "                logger.log_value('Test Recall (l)', accs[0])\n",
    "                logger.log_value('Test Recall (2)', accs[1])\n",
    "                logger.log_value('Test Recall (4)', accs[2])\n",
    "                logger.log_value('Test Recall (8)', accs[3])\n",
    "                logger.log_value('Test Recall (16)', accs[4])\n",
    "                \n",
    "def plot_roc(fpr,tpr,figure_name=\"roc.png\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig = plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig(os.path.join(LOG_DIR,figure_name), dpi=fig.dpi)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer):\n",
    "    \"\"\"Updates the learning rate given the learning rate decay.\n",
    "    The routine has been implemented according to the original Lua SGD optimizer\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        if 'step' not in group:\n",
    "            group['step'] = 0\n",
    "        group['step'] += 1\n",
    "\n",
    "        group['lr'] = args.lr / (1 + group['step'] * args.lr_decay)\n",
    "\n",
    "\n",
    "def create_optimizer(model, new_lr):\n",
    "    # setup optimizer\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=new_lr,\n",
    "                              momentum=0.9, dampening=0.9,\n",
    "                              weight_decay=args.wd)\n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=new_lr,\n",
    "                               weight_decay=args.wd, betas=(args.beta1, 0.999))\n",
    "    elif args.optimizer == 'adagrad':\n",
    "        optimizer = optim.Adagrad(model.parameters(),\n",
    "                                  lr=new_lr,\n",
    "                                  lr_decay=args.lr_decay,\n",
    "                                  weight_decay=args.wd)\n",
    "    return optimizer\n",
    "\n",
    "def main():\n",
    "    #test_display_triplet_distance= True\n",
    "    '''\n",
    "    why test_display_triplet_distance= True in center loss.py?????\n",
    "    '''\n",
    "    test_display_triplet_distance= True\n",
    "    # print the experiment configuration\n",
    "    print('\\nparsed options:\\n{}\\n'.format(vars(args)))\n",
    "    print('\\nNumber of Classes:\\n{}\\n'.format(len(train_dir.classes)))\n",
    "\n",
    "    # instantiate model and initialize weights\n",
    "    #model = FaceModelSoftmax(embedding_size=args.embedding_size,num_classes=len(train_dir.classes),checkpoint=checkpoint)\n",
    "    model = FaceModel(embedding_size=args.embedding_size,\n",
    "                      num_classes=len(train_dir.classes),\n",
    "                      pretrained=False)\n",
    "    if args.cuda:\n",
    "        print(\"you are using gpu\")\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = create_optimizer(model, args.lr)\n",
    "    \n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print('=> loading checkpoint {}'.format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "        else:\n",
    "            checkpoint = None\n",
    "            print('=> no checkpoint found at {}'.format(args.resume))\n",
    "    print(checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    start = args.start_epoch\n",
    "    end = start + args.epochs\n",
    "\n",
    "    for epoch in range(start, end):\n",
    "        train(train_loader, model, optimizer, epoch)\n",
    "#         testRecall(test_loader, model, epoch)\n",
    "        test(test_loader, model, epoch)\n",
    "        testaccuracy(testaccuracy_loader, model, epoch)\n",
    "        if test_display_triplet_distance:\n",
    "            display_triplet_distance_test(model,test_loader,LOG_DIR+\"/test_{}\".format(epoch))\n",
    "            display_triplet_distance(model,train_loader,LOG_DIR+\"/train_{}\".format(epoch))\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
